// app/projects/EditorModal.tsx

// Editor modal component with simple, reliable sentence‚Äëby‚Äësentence TTS and sentence highlighting

/*
 * This component is a rewrite of the original EditorModal for Proselenos.
 * It retains the sentence‚Äëby‚Äësentence text‚Äëto‚Äëspeech (TTS) playback
 * but adds the ability to highlight the current sentence as it is being
 * spoken.  Highlighting is achieved without modifying the underlying
 * markdown editor (MDEditor) by rendering a separate preview panel
 * that mirrors the content and wraps the currently spoken sentence in
 * a span with a yellow background.  Duplicate sentences are handled
 * by computing character ranges sequentially, so the second occurrence
 * of an identical sentence will be highlighted when appropriate.
 */

'use client';

import dynamic from 'next/dynamic';
import { useState, useRef, useEffect } from 'react';
import React from 'react';
import { ThemeConfig } from '../shared/theme';
import { showAlert, showInputAlert } from '../shared/alerts';
import { commands } from '@uiw/react-md-editor';
import '@uiw/react-md-editor/markdown-editor.css';
import '@uiw/react-markdown-preview/markdown.css';

// Dynamically import the markdown editor on the client
const MDEditor = dynamic(() => import('@uiw/react-md-editor'), { ssr: false });

interface EditorModalProps {
  isOpen: boolean;
  theme: ThemeConfig;
  isDarkMode: boolean;
  currentProject: string | null;
  currentProjectId: string | null;
  currentFileName: string | null;
  currentFileId: string | null;
  editorMode: 'new' | 'existing';
  editorContent: string;
  onClose: () => void;
  onContentChange: (content: string) => void;
  onSaveFile: (content: string, filename?: string) => Promise<string | void>;
  onBrowseFiles: () => void;
}

export default function EditorModal({
  isOpen,
  theme,
  isDarkMode,
  currentProject,
  currentProjectId,
  currentFileName,
  currentFileId,
  editorMode,
  editorContent,
  onClose,
  onContentChange,
  onSaveFile,
  onBrowseFiles,
}: EditorModalProps) {
  // State for file saving and opening
  const [isSaving, setIsSaving] = useState(false);
  const [isOpening, setIsOpening] = useState(false);

  // TTS state variables ‚Äì simplified
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [currentSentenceIndex, setCurrentSentenceIndex] = useState(0);
  const [sentences, setSentences] = useState<string[]>([]);

  // Voice selection state
  const [availableVoices, setAvailableVoices] = useState<any[]>([]);
  const [selectedVoice, setSelectedVoice] = useState('en-US-EmmaMultilingualNeural');
  const [isLoadingVoices, setIsLoadingVoices] = useState(false);
  const [isClientHydrated, setIsClientHydrated] = useState(false);

  // Two-buffer system: current + next audio
  const [currentAudio, setCurrentAudio] = useState<HTMLAudioElement | null>(null);
  const [nextAudio, setNextAudio] = useState<HTMLAudioElement | null>(null);
  const [currentAudioUrl, setCurrentAudioUrl] = useState<string | null>(null);
  const [nextAudioUrl, setNextAudioUrl] = useState<string | null>(null);

  const [isGeneratingInitial, setIsGeneratingInitial] = useState(false);
  const [isGeneratingNext, setIsGeneratingNext] = useState(false);

  // Single abort controller for background generation
  const abortControllerRef = useRef<AbortController | null>(null);

  // Ref for immediate access to nextAudio (avoids React state timing issues)
  const nextAudioRef = useRef<{ audio: HTMLAudioElement; url: string } | null>(null);

useEffect(() => {
  console.log(
    'TTS state changed:',
    'isSpeaking =', isSpeaking,
    'isPaused =', isPaused,
    'sentences.length =', sentences.length,
    'currentSentenceIndex =', currentSentenceIndex
  );
}, [isSpeaking, isPaused, sentences, currentSentenceIndex]);



  // Hydrate client on mount
  useEffect(() => {
    setIsClientHydrated(true);
  }, []);

  // Load available voices when client is ready
  useEffect(() => {
    if (!isClientHydrated || typeof window === 'undefined') return;
    const loadVoices = async () => {
      setIsLoadingVoices(true);
      try {
        const edgeTTSModule: any = await import('edge-tts-universal');
        const { VoicesManager } = edgeTTSModule;
        const voicesManager = await VoicesManager.create();
        // Get English voices
        const englishVoices = voicesManager.find({ Language: 'en' });
        setAvailableVoices(englishVoices);
        // Load saved voice preference or use default
        const savedVoice = localStorage.getItem('proselenos-selected-voice');
        if (
          savedVoice &&
          englishVoices.some((voice: any) => voice.ShortName === savedVoice)
        ) {
          setSelectedVoice(savedVoice);
        }
      } catch (error) {
        console.error('Error loading voices:', error);
        // Keep default voice if loading fails
      } finally {
        setIsLoadingVoices(false);
      }
    };
    loadVoices();
  }, [isClientHydrated]);

  // Persist voice selection
  const handleVoiceChange = (voice: string) => {
    if (typeof window === 'undefined') return;
    setSelectedVoice(voice);
    localStorage.setItem('proselenos-selected-voice', voice);
  };

  // Simplified toolbar commands
  const filteredCommands = [
    commands.bold,
    commands.italic,
    commands.strikethrough,
    commands.hr,
    commands.divider,
    commands.title,
    commands.quote,
    commands.unorderedListCommand,
    commands.orderedListCommand,
    commands.checkedListCommand,
  ];

  // Utility to parse text into sentences
  const parseSentences = (text: string): string[] => {
    if (!text.trim()) return [];
    const result = text
      .replace(/\n\s*\n+/g, ' . ') // Normalize multiple blank lines
      .replace(/([.!?])\s*\n+/g, '$1 ') // Remove newline after punctuation
      .replace(/\n+/g, ' ') // Replace newlines with space
      .split(/(?<=[.!?])\s+(?=[A-Z])/)
      .map((s) => s.trim())
      .filter((s) => s.length > 0);
    return result;
  };

  // Count words in the editor
  const countWords = (text: string) => {
    return text
      .replace(/(\r\n|\r|\n)/g, ' ')
      .split(/\s+/)
      .filter((word) => word.length > 0)
      .length;
  };

  // Compute the current word count for display
  const wordCount = countWords(editorContent);

  // Save file handler
  const handleSave = async () => {
    if (!editorContent.trim()) {
      showAlert('Cannot save empty content!', 'error', undefined, isDarkMode);
      return;
    }
    if (currentFileName && currentFileName.match(/proselenos.*\.json$/i)) {
      showAlert('Cannot edit configuration files!', 'error', undefined, isDarkMode);
      return;
    }
    setIsSaving(true);
    try {
      if (editorMode === 'existing' && currentFileId) {
        await onSaveFile(editorContent);
        showAlert('‚úÖ File updated successfully!', 'success', undefined, isDarkMode);
      } else {
        if (!currentProject || !currentProjectId) {
          showAlert('Please select a Project to save new files!', 'error', undefined, isDarkMode);
          return;
        }
        const defaultName = `manuscript_${new Date().toISOString().slice(0, 10)}`;
        const fileName = await showInputAlert(
          'Enter filename (without .txt extension):',
          defaultName,
          'Enter filename...',
          isDarkMode
        );
        if (!fileName) {
          setIsSaving(false);
          return;
        }
        await onSaveFile(editorContent, fileName);
        showAlert('‚úÖ File saved successfully!', 'success', undefined, isDarkMode);
      }
    } catch (error) {
      showAlert('‚ùå Error saving file!', 'error', undefined, isDarkMode);
    } finally {
      setIsSaving(false);
    }
  };

  // Open file handler
  const handleOpen = async () => {
    setIsOpening(true);
    try {
      onBrowseFiles();
    } finally {
      setIsOpening(false);
    }
  };

  // Generate single sentence audio with cancellation support
  const generateSentenceAudio = async (
    sentence: string
  ): Promise<{ audio: HTMLAudioElement; url: string } | null> => {
    if (!sentence.trim() || typeof window === 'undefined') return null;
    try {
      const edgeTTSModule: any = await import('edge-tts-universal');
      const TTSConstructor = edgeTTSModule.EdgeTTS;
      const tts = new TTSConstructor(sentence, selectedVoice);
      const result = await tts.synthesize();
      const audioBlob = new Blob([result.audio], { type: 'audio/mpeg' });
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      audio.preload = 'auto';
      return { audio, url: audioUrl };
    } catch (error) {
      console.error('Error generating sentence audio:', error);
      return null;
    }
  };

  // Generate next sentence in background (with state tracking)
  const generateNextSentence = async (nextIndex: number, sentenceArray: string[]) => {
    if (nextIndex >= sentenceArray.length) return;
    if (isGeneratingNext) return;
    const sentence = sentenceArray[nextIndex];
    if (!sentence.trim()) return;
    // Cancel any previous generation
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
    const newAbortController = new AbortController();
    abortControllerRef.current = newAbortController;
    setIsGeneratingNext(true);
    try {
      const result = await generateSentenceAudio(sentence);
      // Check if cancelled
      if (newAbortController.signal.aborted) {
        return;
      }
      if (result) {
        // Store in ref for immediate access (fixes race condition)
        nextAudioRef.current = result;
        // Also update state for UI
        setNextAudio(result.audio);
        setNextAudioUrl(result.url);
      } else {
        nextAudioRef.current = null;
      }
    } catch (error) {
      if (!newAbortController.signal.aborted) {
        console.error(`Error generating sentence ${nextIndex}:`, error);
      }
    } finally {
      setIsGeneratingNext(false);
    }
  };

  // Handle sentence completion and advance
  const advanceToNextSentence = async (
    finishedIndex: number,
    sentenceArray: string[]
  ) => {
    const nextIndex = finishedIndex + 1;
    if (nextIndex >= sentenceArray.length) {
      // Completed all sentences
      cleanupAudio();
      return;
    }
    // Cleanup finished audio
    if (currentAudioUrl) {
      URL.revokeObjectURL(currentAudioUrl);
    }
    // Check if nextAudio is ready (use ref for immediate access)
    const nextAudioData = nextAudioRef.current;
    if (!nextAudioData) {
      // Emergency: generate next sentence synchronously
      const sentence = sentenceArray[nextIndex];
      if (sentence.trim()) {
        setIsGeneratingNext(true);
        const result = await generateSentenceAudio(sentence);
        setIsGeneratingNext(false);
        if (result) {
          setCurrentAudio(result.audio);
          setCurrentAudioUrl(result.url);
          setNextAudio(null);
          setNextAudioUrl(null);
          setCurrentSentenceIndex(nextIndex);
          // Mark speaking before playback
          setIsSpeaking(true);
          setIsPaused(false);
          // Start playing
          result.audio.onended = () => advanceToNextSentence(nextIndex, sentenceArray);
          result.audio.onerror = () => {
            showAlert('Audio playback error', 'error', undefined, isDarkMode);
            cleanupAudio();
          };
          await result.audio.play();
          // Start generating the sentence after this one
          generateNextSentence(nextIndex + 1, sentenceArray);
        } else {
          showAlert('Failed to generate next sentence', 'error', undefined, isDarkMode);
          cleanupAudio();
        }
      }
      return;
    }
    // Normal path: nextAudio is ready
    setCurrentAudio(nextAudioData.audio);
    setCurrentAudioUrl(nextAudioData.url);
    nextAudioRef.current = null;
    setNextAudio(null);
    setNextAudioUrl(null);
    setCurrentSentenceIndex(nextIndex);
    // Mark speaking before playback
    setIsSpeaking(true);
    setIsPaused(false);
    // Start playing immediately
    nextAudioData.audio.onended = () => advanceToNextSentence(nextIndex, sentenceArray);
    nextAudioData.audio.onerror = () => {
      showAlert('Audio playback error', 'error', undefined, isDarkMode);
      cleanupAudio();
    };
    await nextAudioData.audio.play();
    // Start generating the next sentence in background
    generateNextSentence(nextIndex + 1, sentenceArray);
  };

  // Main TTS handler (Speak/Pause/Resume)
  const handleSpeak = async (): Promise<void> => {
    if (!isClientHydrated || typeof window === 'undefined') {
      showAlert('TTS not available during page load', 'error', undefined, isDarkMode);
      return;
    }
    if (!editorContent.trim()) {
      showAlert('No content to read!', 'error', undefined, isDarkMode);
      return;
    }
    if (isSpeaking && !isPaused) {
      handlePause();
      return;
    }
    if (isPaused) {
      handleResume();
      return;
    }
    const parsedSentences = parseSentences(
      editorContent.replace(/^(?:[ \t]*\r?\n){1,2}/, '')
    );
    if (parsedSentences.length === 0) {
      showAlert('No sentences found!', 'error', undefined, isDarkMode);
      return;
    }
    setSentences(parsedSentences);
    setCurrentSentenceIndex(0);
    // Initial generation (user expects this wait)
    setIsGeneratingInitial(true);
    const result0 = await generateSentenceAudio(parsedSentences[0]);
    setIsGeneratingInitial(false);
    if (!result0) {
      showAlert('Failed to generate speech', 'error', undefined, isDarkMode);
      return;
    }
    setCurrentAudio(result0.audio);
    setCurrentAudioUrl(result0.url);
    /*
     * Explicitly mark the TTS as speaking before playing to ensure
     * the highlight preview becomes visible immediately.  Relying
     * solely on the `onplay` event can lead to a race condition
     * where `isSpeaking` remains false and the highlight never renders.
     */
    setIsSpeaking(true);
    setIsPaused(false);
    // Start playing sentence 0
    result0.audio.onended = () => advanceToNextSentence(0, parsedSentences);
    result0.audio.onerror = () => {
      showAlert('Audio playback error', 'error', undefined, isDarkMode);
      cleanupAudio();
    };
    await result0.audio.play();
    // Start generating sentence 1 while sentence 0 plays
    if (parsedSentences.length > 1) {
      generateNextSentence(1, parsedSentences);
    }
  };

  // Pause/resume/stop handlers
  const handlePause = (): void => {
    if (currentAudio && isSpeaking && !isPaused) {
      currentAudio.pause();
      setIsPaused(true);
    }
  };
  const handleResume = (): void => {
    if (currentAudio && isPaused) {
      currentAudio.play();
      setIsPaused(false);
    }
  };
  const handleStop = (): void => {
    // Force stop any currently playing audio immediately
    if (currentAudio) {
      currentAudio.pause();
      currentAudio.currentTime = 0;
    }
    // Force stop any buffered audio
    if (nextAudio) {
      nextAudio.pause();
      nextAudio.currentTime = 0;
    }
    // Force stop ref‚Äëstored audio
    if (nextAudioRef.current?.audio) {
      nextAudioRef.current.audio.pause();
      nextAudioRef.current.audio.currentTime = 0;
    }
    cleanupAudio();
  };

  // Cleanup function for audio and TTS state
  const cleanupAudio = () => {
    setIsSpeaking(false);
    setIsPaused(false);
    setCurrentSentenceIndex(0);
    setSentences([]);
    setCurrentAudio(null);
    setNextAudio(null);
    setCurrentAudioUrl(null);
    setNextAudioUrl(null);
    setIsGeneratingInitial(false);
    setIsGeneratingNext(false);
  };

  // Cleanup when component unmounts
  useEffect(() => {
    return () => {
      if (typeof window !== 'undefined') {
        cleanupAudio();
      }
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Cleanup when modal closes
  useEffect(() => {
    if (!isOpen && typeof window !== 'undefined') {
      cleanupAudio();
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isOpen]);

  /*
   * Build a highlighted HTML string.  To avoid issues with whitespace
   * differences between the normalized sentences returned by
   * `parseSentences()` and the original `editorContent`, we split the
   * original content using the same sentence boundary regex.  We then
   * wrap only the current sentence in a span.  This approach preserves
   * duplicate sentences and avoids missing matches when line breaks or
   * multiple spaces are present.
   */
  const getHighlightedHtml = () => {
    // Normalize line breaks to spaces similar to parseSentences()
    const normalized = editorContent
      .replace(/\n\s*\n+/g, ' . ') // Normalize multiple blank lines
      .replace(/([.!?])\s*\n+/g, '$1 ') // Remove newline after punctuation
      .replace(/\n+/g, ' '); // Replace remaining newlines with space
    // Split into sentence‚Äëlike parts, keeping order
    const parts = normalized.split(/(?<=[.!?])\s+(?=[A-Z])/);
    // Recombine parts, highlighting the current sentence when speaking
    return parts
      .map((part, idx) => {
        if (idx === currentSentenceIndex && isSpeaking) {
          return `<span style="background-color: yellow;">${part}</span>`;
        }
        return part;
      })
      .join(' ');
  };

  // Do not render anything if modal is closed
  if (!isOpen) return null;

  return (
    <div
      style={{
        position: 'fixed',
        zIndex: 1000,
        top: 0,
        left: 0,
        width: '100%',
        height: '100%',
        overflow: 'auto',
        backgroundColor: theme.modalBg,
        color: theme.text,
        padding: '0.5rem',
      }}
    >
      {/* Header bar */}
      <div
        style={{
          display: 'flex',
          justifyContent: 'space-between',
          alignItems: 'center',
          padding: '0.5rem',
          borderBottom: `1px solid ${theme.border}`,
          flexWrap: 'wrap',
        }}
      >
        <div style={{ marginRight: '0.5rem' }}>
          <span role="img" aria-label="note">
            üìù
          </span>{' '}
          Editor: {currentProject || 'New Project'}
          {currentFileName && ` - ${currentFileName}`}
        </div>
        <div style={{ marginRight: '0.5rem' }}>{wordCount.toLocaleString()} words</div>
        {isSpeaking && sentences.length > 0 && (
          <div style={{ marginRight: '0.5rem' }}>
            (Sentence {currentSentenceIndex + 1} of {sentences.length})
            {isGeneratingNext && ' ‚Ä¢ Generating...'}
          </div>
        )}
        {/* Right side: action buttons */}
        <div style={{ display: 'flex', gap: '0.5rem', flexWrap: 'wrap' }}>
          <button
            onClick={handleSave}
            disabled={isSaving}
            title={editorMode === 'existing' ? 'Update file' : 'Save as .txt'}
            style={{
              padding: '3px 8px',
              backgroundColor: theme.modalBg,
              color: theme.text,
              border: `1px solid ${theme.border}`,
              borderRadius: '3px',
              fontSize: '11px',
              cursor: isSaving ? 'not-allowed' : 'pointer',
            }}
          >
            {isSaving ? 'Saving‚Ä¶' : editorMode === 'existing' ? 'Update' : 'Save as .txt'}
          </button>
          <button
            onClick={handleOpen}
            disabled={isOpening}
            title="Open file"
            style={{
              padding: '3px 8px',
              backgroundColor: theme.modalBg,
              color: theme.text,
              border: `1px solid ${theme.border}`,
              borderRadius: '3px',
              fontSize: '11px',
              cursor: isOpening ? 'not-allowed' : 'pointer',
            }}
          >
            {isOpening ? 'Opening‚Ä¶' : 'Open'}
          </button>
          <select
            value={selectedVoice}
            onChange={(e) => handleVoiceChange(e.target.value)}
            disabled={!isClientHydrated || isSpeaking || isLoadingVoices}
            title="Select voice for text-to-speech"
            style={{
              padding: '3px 6px',
              backgroundColor:
                !isClientHydrated || isSpeaking || isLoadingVoices ? '#6c757d' : theme.modalBg,
              color: theme.text,
              border: `1px solid ${theme.border}`,
              borderRadius: '3px',
              fontSize: '11px',
              cursor:
                !isClientHydrated || isSpeaking || isLoadingVoices ? 'not-allowed' : 'pointer',
              maxWidth: '140px',
            }}
          >
            {!isClientHydrated ? (
              <option>Initializing...</option>
            ) : isLoadingVoices ? (
              <option>Loading voices...</option>
            ) : (
              availableVoices.map((voice: any) => {
                const displayName = voice.ShortName
                  .replace(/^[a-z]{2}-[A-Z]{2}-/, '')
                  .replace(/Neural$|Multilingual$|MultilingualNeural$/, '')
                  .replace(/([A-Z])/g, ' $1')
                  .trim();
                const locale = voice.Locale?.replace('en-', '') || '';
                const gender = voice.Gender || '';
                return (
                  <option key={voice.ShortName} value={voice.ShortName}>
                    {displayName} ({locale} {gender})
                  </option>
                );
              })
            )}
          </select>
          <button
            onClick={handleSpeak}
            disabled={!isClientHydrated || isLoadingVoices || isGeneratingInitial}
            title="Speak / Pause / Resume"
            style={{
              padding: '3px 8px',
              backgroundColor: theme.modalBg,
              color: theme.text,
              border: `1px solid ${theme.border}`,
              borderRadius: '3px',
              fontSize: '11px',
              cursor:
                !isClientHydrated || isLoadingVoices || isGeneratingInitial
                  ? 'not-allowed'
                  : 'pointer',
            }}
          >
            {!isClientHydrated
              ? 'Loading‚Ä¶'
              : isLoadingVoices
              ? 'Loading‚Ä¶'
              : isGeneratingInitial
              ? 'Generating‚Ä¶'
              : isSpeaking
              ? isPaused
                ? '‚ñ∂Ô∏è Resume'
                : '‚è∏Ô∏è Pause'
              : 'üîä Speak'}
          </button>
          <button
            onClick={handleStop}
            disabled={!isSpeaking && !isPaused}
            title="Stop speaking"
            style={{
              padding: '3px 8px',
              backgroundColor: theme.modalBg,
              color: theme.text,
              border: `1px solid ${theme.border}`,
              borderRadius: '3px',
              fontSize: '11px',
              cursor: !isSpeaking && !isPaused ? 'not-allowed' : 'pointer',
            }}
          >
            ‚èπÔ∏è Quiet
          </button>
          <button
            onClick={() => {
              cleanupAudio();
              onClose();
            }}
            style={{
              padding: '3px 8px',
              backgroundColor: '#6c757d',
              color: '#fff',
              border: 'none',
              borderRadius: '3px',
              fontSize: '11px',
              cursor: 'pointer',
            }}
          >
            Close
          </button>
        </div>
      </div>
      {/* Highlighted preview panel - show only when speaking */}
      {isSpeaking && sentences.length > 0 && (
        <div
          style={{
            whiteSpace: 'pre-wrap',
            padding: '0.5rem',
            marginTop: '0.5rem',
            border: `1px solid ${theme.border}`,
            borderRadius: '4px',
            backgroundColor: isDarkMode ? '#343a40' : '#f8f9fa',
            color: theme.text,
            minHeight: '6rem',
            pointerEvents: 'none',
          }}
          dangerouslySetInnerHTML={{ __html: getHighlightedHtml() }}
        />
      )}
      {/* Editor body */}
      <div style={{ marginTop: '0.5rem' }}>
        <MDEditor
          value={editorContent}
          onChange={(val) => onContentChange(val || '')}
          height={typeof window !== 'undefined' ? window.innerHeight - 200 : 400}
          preview="edit"
          hideToolbar={false}
          commands={filteredCommands}
          textareaProps={{
            placeholder: `Write your content for ${currentProject || 'your project'}...`,
            style: {
              fontSize: '14px',
              lineHeight: '1.6',
              fontFamily: 'Georgia, serif',
            },
          }}
        />
      </div>
    </div>
  );
}